{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Solution to the F20 final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np, scipy as sp, pandas as pd, pymc3 as pm, matplotlib.pyplot as plt, arviz as az\n",
    "from scipy import stats"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Problem 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>home</th>\n",
       "      <th>favorite</th>\n",
       "      <th>underdog</th>\n",
       "      <th>spread</th>\n",
       "      <th>favorite_name</th>\n",
       "      <th>underdog_name</th>\n",
       "      <th>week</th>\n",
       "      <th>diff</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>0</td>\n",
       "      <td>17</td>\n",
       "      <td>23</td>\n",
       "      <td>7.0</td>\n",
       "      <td>LAN</td>\n",
       "      <td>NO</td>\n",
       "      <td>2</td>\n",
       "      <td>-6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>1</td>\n",
       "      <td>28</td>\n",
       "      <td>23</td>\n",
       "      <td>7.0</td>\n",
       "      <td>SD</td>\n",
       "      <td>DET</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>1</td>\n",
       "      <td>35</td>\n",
       "      <td>23</td>\n",
       "      <td>7.0</td>\n",
       "      <td>LAN</td>\n",
       "      <td>GB</td>\n",
       "      <td>3</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>1</td>\n",
       "      <td>20</td>\n",
       "      <td>10</td>\n",
       "      <td>7.0</td>\n",
       "      <td>LAA</td>\n",
       "      <td>SEA</td>\n",
       "      <td>3</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56</th>\n",
       "      <td>1</td>\n",
       "      <td>23</td>\n",
       "      <td>17</td>\n",
       "      <td>7.0</td>\n",
       "      <td>BUF</td>\n",
       "      <td>IND</td>\n",
       "      <td>5</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    home  favorite  underdog  spread favorite_name underdog_name  week  diff\n",
       "21     0        17        23     7.0           LAN            NO     2    -6\n",
       "24     1        28        23     7.0            SD           DET     2     5\n",
       "35     1        35        23     7.0           LAN            GB     3    12\n",
       "37     1        20        10     7.0           LAA           SEA     3    10\n",
       "56     1        23        17     7.0           BUF           IND     5     6"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scores = pd.read_csv('spread7.csv', index_col = 0)\n",
    "scores.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, we compute the following probabilities assuming that the quantity $y = (\\mbox{outcome} - \\mbox{point spread})$ has a distribution $N(0, 14^2)$:\n",
    "\n",
    "$$\n",
    "\\begin{align*}\n",
    "&P(\\mbox{favorite wins $|$ spread = 7}) \\\\\n",
    "&P(\\mbox{favorite wins by at least 7 $|$ spread = 7} ) \\\\\n",
    "&P(\\mbox{favorite wins by at least 7 $|$ spread = 7 and favorite wins} ) \\\\\n",
    "\\end{align*}\n",
    "$$\n",
    "\n",
    "The favorite wins if $y > -7$, so we have\n",
    "$$\n",
    "\\begin{align*}\n",
    "&P(\\mbox{favorite wins $|$ spread = 7}) = \\frac{1}{\\sqrt{2\\pi 14^2}} \\int_{-7}^\\infty \\exp\\left(-\\frac{1}{2}\\frac{(y - 7)^2}{14^2}\\right) dy \\approx 0.6915\n",
    "\\end{align*}\n",
    "$$\n",
    "where we compute the approximation with:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6914624612740131"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "1-sp.stats.norm(0, 14).cdf(-7)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The favorite wins by at least 7 if $y \\geq 0$, which has probability 0.5.\n",
    "\n",
    "Finally, we can use the definition of conditional probability to find the last probability:\n",
    "\n",
    "$$ P(\\mbox{favorite wins by at least 7 $|$ spread = 7 and favorite wins} ) = \\frac{P(\\mbox{favorite wins by at least 7 $|$ spread = 7} )}{P(\\mbox{favorite wins $|$ spread = 7})} \\approx 0.7231 $$\n",
    "\n",
    "For a comparison, we compute the empirical probabilities from the data set:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "P(fav wins): 0.7737226277372263\n",
      "P(fav wins by 7): 0.5474452554744526\n",
      "P(fav wins by 7 | fav wins): 0.7075471698113207\n"
     ]
    }
   ],
   "source": [
    "print('P(fav wins):', sum(scores['diff'] > 0) / len(scores))\n",
    "print('P(fav wins by 7):', sum(scores['diff'] >= 7) / len(scores))\n",
    "print('P(fav wins by 7 | fav wins):', sum(scores['diff'] >= 7) / sum(scores['diff'] > 0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The first probability is not approximated very well, although the others are better. This may be attributable to the fact that a game ending in a tie score continues for an \"overtime\" period, reducing the probability that the final score is exactly 0 and transferring that probability mass to neighboring scores (this might be thought of as a \"zero-deflated\" process), meaning that the continuous approximation fares especially poorly near $y = 0$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Problem 2\n",
    "\n",
    "We'll show two approaches: First, computing the predictive probability explicitly by integrating over the posterior distribution; second, estimating it by sampling from the posterior predictive distribution. Skip to **alternative approach** below if you don't want to deal with integrals :)\n",
    "\n",
    "First, we consider the hypothesis that the intermediate data showed 8 cases in the vaccine arm and 86 in the placebo arm. Under this hypothesis, and the model\n",
    "$$\n",
    "\\begin{align*}\n",
    "y &\\sim \\mathrm{Binomial}(n, \\theta) \\\\\n",
    "\\theta &\\sim \\mathrm{Beta}(0.7, 1.0) \\\\\n",
    "\\end{align*}\n",
    "$$\n",
    "the posterior distribution is $\\theta | y_{\\mathrm{obs}} \\sim \\mathrm{Beta}(0.7 + 8, 1 + 86)$.\n",
    "\n",
    "If this is the case, then the remaining data consists of 82 cases in the placebo arm and 0 in the vaccine arm; denote this as $y' = 0$.\n",
    "To compute the posterior predictive probability of this, we marginalize over $\\theta$:\n",
    "\n",
    "$$ \n",
    "\\begin{align*}\n",
    "p(y' = 0 | y_{\\mathrm{obs}}) &= \\int_0^1 p(y' = 0 | \\theta) p(\\theta | y_{\\mathrm{obs}}) d\\theta  \\\\\n",
    "&= \\frac{1}{B(8.7, 87)}\\int_0^1 (1 - \\theta)^{82} \\theta^{7.7} (1 - \\theta)^{86} d\\theta \\\\\n",
    "&= \\frac{1}{B(8.7, 87)}\\int_0^1 \\theta^{7.7} (1 - \\theta)^{168} d\\theta\n",
    "\\end{align*}\n",
    "$$\n",
    "\n",
    "where $B(8.7, 87)$ is the normalizing constant for a $\\mathrm{Beta(8.7, 87)}$ distribution.\n",
    "\n",
    "We can compute this either using numerical integration, or with repeated integration by parts. Starting with the normalizing constant,\n",
    "$$\n",
    "B(8.7, 87) = \\int_0^1 \\theta^{7.7} (1-\\theta)^{86} d\\theta\n",
    "$$\n",
    "Integrating by parts once,\n",
    "$$\n",
    "\\int_0^1 \\theta^{7.7} (1-\\theta)^{86} d\\theta = \\frac{86}{8.7} \\int_0^1 \\theta^{8.7} (1-\\theta)^{85} d\\theta\n",
    "$$\n",
    "Repeating until the power on $(1 - \\theta)$ is zero,\n",
    "$$\n",
    "\\int_0^1 \\theta^{7.7} (1-\\theta)^{86} d\\theta = \\frac{86!}{(8.7)(9.7)\\ldots(93.7)} \\int_0^1 \\theta^{93.7}d\\theta = \\frac{86!}{(8.7)(9.7)\\ldots(94.7)}\n",
    "$$\n",
    "\n",
    "So,\n",
    "$$\n",
    "B(8.7, 87) =  \\frac{86!}{(8.7)(9.7)\\ldots(94.7)}\n",
    "$$\n",
    "and,\n",
    "$$\n",
    "p(y' = 0 | y_{\\mathrm{obs}}) = \\frac{(8.7)(9.7)\\ldots(94.7)}{86!} \\int_0^1 \\theta^{7.7} (1 - \\theta)^{168} d\\theta\n",
    "$$\n",
    "The integral has the same form as the beta integral, so we can just apply the same technique:\n",
    "$$\n",
    "p(y' = 0 | y_{\\mathrm{obs}}) = \\frac{(8.7)(9.7)\\ldots(94.7)}{86!} \\frac{168!}{(8.7)(9.7)\\ldots(176.7)} \\approx 0.0037\n",
    "$$\n",
    "Below we compute using the exact formula and by numerical integration, confirming that they produce approximately the same result."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.9631007157014142e-13\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "1.9631007157013905e-13"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b = 1\n",
    "for i in range(86):\n",
    "    b *= (86 - i) / (8.7 + i)\n",
    "b /= 94.7\n",
    "print(b)\n",
    "sp.special.beta(8.7, 87) # make sure we didn't mess up :)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.003704002854739326"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "p = 1\n",
    "for i in range(168):\n",
    "    p *= (168 - i) / (8.7 + i)\n",
    "p /= 176.7\n",
    "p / b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0037042653645103425"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from scipy import integrate\n",
    "f = lambda t: (t ** 7.7) * (1 - t) ** 168\n",
    "sp.integrate.quad(f, 0, 1)[0] / sp.special.beta(8.7, 87)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "By the same approach, under the second hypothesis, the posterior distribution is $\\theta | y_{\\mathrm{obs}} \\sim \\mathrm{Beta}(0.7 + 3, 1 + 91)$, and the remaining data consist of 5 cases in the vaccine arm and 77 in the placebo arm.\n",
    "\n",
    "Then, \n",
    "$$ \n",
    "\\begin{align*}\n",
    "p(y' = 5 | y_{\\mathrm{obs}}) &= \\int_0^1 p(y' = 0 | \\theta) p(\\theta | y_{\\mathrm{obs}}) d\\theta  \\\\\n",
    "&= \\frac{1}{B(3.7, 92)}\\left(\\begin{array}{c}82\\\\5\\end{array}\\right)\\int_0^1 \\theta^5 (1 - \\theta)^{77} \\theta^{2.7} (1 - \\theta)^{91} d\\theta \\\\\n",
    "&= \\frac{1}{B(3.7, 92)}\\left(\\begin{array}{c}82\\\\5\\end{array}\\right)\\int_0^1 \\theta^{7.7} (1 - \\theta)^{168} d\\theta\n",
    "\\end{align*}\n",
    "$$\n",
    "\n",
    "Integrating by parts again,\n",
    "$$\n",
    "p(y' = 5 | y_{\\mathrm{obs}}) = \\left(\\begin{array}{c}82\\\\5\\end{array}\\right) \\frac{(3.7)(4.7) \\ldots (94.7)}{91!} \\frac{168!}{(8.7)(9.7)\\ldots(176.7)} \\approx 0.0926\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.09261146436606198"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Exact formula\n",
    "b = 1\n",
    "for i in range(91):\n",
    "    b *= (91 - i) / (3.7 + i)\n",
    "b /= 94.7\n",
    "p = 1\n",
    "for i in range(168):\n",
    "    p *= (168 - i) / (8.7 + i)\n",
    "p /= 176.7\n",
    "(p / b) * sp.special.binom(82, 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.09261146436820741"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Numerical integration\n",
    "g = lambda t: sp.special.binom(82,5) * (t ** 7.7) * (1 - t) ** 168\n",
    "sp.integrate.quad(g, 0, 1)[0] / sp.special.beta(3.7, 92)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This suggests that of these two hypotheses, the second is more plausible: the first yields a predictive probability of 0.0037 for the new data; the second, 0.0926.\n",
    "\n",
    "**Alternative approach:** We could approximate these results by sampling -- generating values of $\\theta$ from the posterior and then sampling the corresponding binomial distribution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0042\n",
      "0.0872\n"
     ]
    }
   ],
   "source": [
    "posterior_1 = sp.stats.beta(8.7, 87)\n",
    "posterior_2 = sp.stats.beta(3.7, 92)\n",
    "\n",
    "post_smp_1 = posterior_1.rvs(5000)\n",
    "post_smp_2 = posterior_2.rvs(5000)\n",
    "\n",
    "post_pred_1 = [sp.stats.binom(82, p).rvs() for p in post_smp_1]\n",
    "post_pred_2 = [sp.stats.binom(82, p).rvs() for p in post_smp_2]\n",
    "print(post_pred_1.count(0) / 5000)        # How many times do we see 0 vaccine cases?\n",
    "print(post_pred_2.count(5) / 5000)        # How many times do we see 5 vaccine cases?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Problem 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>discipline</th>\n",
       "      <th>gender</th>\n",
       "      <th>applications</th>\n",
       "      <th>awards</th>\n",
       "      <th>genderid</th>\n",
       "      <th>discid</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Chemical sciences</td>\n",
       "      <td>m</td>\n",
       "      <td>83</td>\n",
       "      <td>22</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Chemical sciences</td>\n",
       "      <td>f</td>\n",
       "      <td>39</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Physical sciences</td>\n",
       "      <td>m</td>\n",
       "      <td>135</td>\n",
       "      <td>26</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Physical sciences</td>\n",
       "      <td>f</td>\n",
       "      <td>39</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Physics</td>\n",
       "      <td>m</td>\n",
       "      <td>67</td>\n",
       "      <td>18</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Physics</td>\n",
       "      <td>f</td>\n",
       "      <td>9</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Humanities</td>\n",
       "      <td>m</td>\n",
       "      <td>230</td>\n",
       "      <td>33</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Humanities</td>\n",
       "      <td>f</td>\n",
       "      <td>166</td>\n",
       "      <td>32</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Technical sciences</td>\n",
       "      <td>m</td>\n",
       "      <td>189</td>\n",
       "      <td>30</td>\n",
       "      <td>1</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Technical sciences</td>\n",
       "      <td>f</td>\n",
       "      <td>62</td>\n",
       "      <td>13</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Interdisciplinary</td>\n",
       "      <td>m</td>\n",
       "      <td>105</td>\n",
       "      <td>12</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Interdisciplinary</td>\n",
       "      <td>f</td>\n",
       "      <td>78</td>\n",
       "      <td>17</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Earth/life sciences</td>\n",
       "      <td>m</td>\n",
       "      <td>156</td>\n",
       "      <td>38</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Earth/life sciences</td>\n",
       "      <td>f</td>\n",
       "      <td>126</td>\n",
       "      <td>18</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>Social sciences</td>\n",
       "      <td>m</td>\n",
       "      <td>425</td>\n",
       "      <td>65</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>Social sciences</td>\n",
       "      <td>f</td>\n",
       "      <td>409</td>\n",
       "      <td>47</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>Medical sciences</td>\n",
       "      <td>m</td>\n",
       "      <td>245</td>\n",
       "      <td>46</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>Medical sciences</td>\n",
       "      <td>f</td>\n",
       "      <td>260</td>\n",
       "      <td>29</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             discipline gender  applications  awards  genderid  discid\n",
       "0     Chemical sciences      m            83      22         1       0\n",
       "1     Chemical sciences      f            39      10         0       0\n",
       "2     Physical sciences      m           135      26         1       5\n",
       "3     Physical sciences      f            39       9         0       5\n",
       "4               Physics      m            67      18         1       6\n",
       "5               Physics      f             9       2         0       6\n",
       "6            Humanities      m           230      33         1       2\n",
       "7            Humanities      f           166      32         0       2\n",
       "8    Technical sciences      m           189      30         1       8\n",
       "9    Technical sciences      f            62      13         0       8\n",
       "10    Interdisciplinary      m           105      12         1       3\n",
       "11    Interdisciplinary      f            78      17         0       3\n",
       "12  Earth/life sciences      m           156      38         1       1\n",
       "13  Earth/life sciences      f           126      18         0       1\n",
       "14      Social sciences      m           425      65         1       7\n",
       "15      Social sciences      f           409      47         0       7\n",
       "16     Medical sciences      m           245      46         1       4\n",
       "17     Medical sciences      f           260      29         0       4"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.preprocessing import OrdinalEncoder, LabelEncoder\n",
    "\n",
    "grants = pd.read_csv('NWOGrants.csv', sep = ';')\n",
    "#grants['gender_m'] = (grants.gender == 'm').astype(np.int64)\n",
    "#grants['gender_f'] = (grants.gender == 'f').astype(np.int64)\n",
    "grants['genderid'] = LabelEncoder().fit_transform(grants.gender)\n",
    "grants['discid'] = OrdinalEncoder().fit_transform(grants[['discipline']]).astype(np.int64)\n",
    "grants"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We start with a simple model that only includes gender. Below is a forest plot for the intercept (interpreted as a baseline funding probability), and the slope (interpreted as the total effect of gender)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/dylan/.conda/envs/info510/lib/python3.8/site-packages/pymc3/sampling.py:466: FutureWarning: In an upcoming release, pm.sample will return an `arviz.InferenceData` object instead of a `MultiTrace` by default. You can pass return_inferencedata=True or return_inferencedata=False to be safe and silence this warning.\n",
      "  warnings.warn(\n",
      "Auto-assigning NUTS sampler...\n",
      "Initializing NUTS using jitter+adapt_diag...\n",
      "Multiprocess sampling (4 chains in 4 jobs)\n",
      "NUTS: [bm, a]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "        <style>\n",
       "            /* Turns off some styling */\n",
       "            progress {\n",
       "                /* gets rid of default border in Firefox and Opera. */\n",
       "                border: none;\n",
       "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "                background-size: auto;\n",
       "            }\n",
       "            .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "                background: #F44336;\n",
       "            }\n",
       "        </style>\n",
       "      <progress value='36000' class='' max='36000' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      100.00% [36000/36000 00:10<00:00 Sampling 4 chains, 0 divergences]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Sampling 4 chains for 3_000 tune and 6_000 draw iterations (12_000 + 24_000 draws total) took 11 seconds.\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x417.6 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "with pm.Model() as univariate_model:\n",
    "    a = pm.Normal('a', 0, 4)\n",
    "    bm = pm.Normal('bm', 0, 0.2)\n",
    "    #bf = pm.Normal('bf', 0, 0.2)\n",
    "    p = pm.math.invlogit(a + bm * grants.genderid )# + bf * grants.gender_f)\n",
    "    y = pm.Binomial('y', p=p, n=grants.applications, observed = grants.awards)\n",
    "    \n",
    "    trace_univariate = pm.sample(6000, target_accept = 0.9, tune = 3000, chains = 4, cores = 4)\n",
    "    summary_univariate = az.summary(trace_univariate, var_names = ['a', 'bm'])\n",
    "    az.plot_forest(trace_univariate, var_names = ['a', 'bm'])\n",
    "    #pm.traceplot(trace_univariate) # Commenting out because this spits a ton of matplotlib warnings on my current environment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, the model including discipline, in the form of 9 varying intercepts."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with pm.Model() as bivariate_model:\n",
    "    a = pm.Normal('a', 0, 4)\n",
    "    bd = pm.Normal('bd', 0, 0.5, shape = 9)\n",
    "    \n",
    "    bm = pm.Normal('bm', 0, 0.5)\n",
    "    p = pm.math.invlogit(a + bd[grants.discid.values] + bm * grants.genderid)\n",
    "    y = pm.Binomial('y', p=p, n=grants.applications, observed = grants.awards)\n",
    "    \n",
    "    trace_bivariate = pm.sample(6000, target_accept = 0.9, tune = 3000, chains = 4, cores = 4)\n",
    "    summary_bivariate = pm.summary(trace_bivariate, var_names = ['a', 'bm', 'bd'])\n",
    "    pm.forestplot(trace_bivariate, var_names = ['a', 'bd', 'bm'])\n",
    "    #pm.traceplot(trace_bivariate)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We see some variation accounted for by discipline, including a few disciplines that are funded at especially high (e.g. physics) or low (e.g. social sciences) rates. (Sorry, social scientists!) Finally, let's compare the posterior distributions of the slopes for each model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pm.plot_posterior(trace_univariate, var_names = ['bm'])\n",
    "pm.plot_posterior(trace_bivariate, var_names = ['bm'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From the above, we see that in both cases, most of the posterior probability mass lies above 0, suggesting that grants from male applicants are funded at a higher rate. A small amount of this difference is accounted for by discipline, as the model conditioning for discipline has a slightly lower posterior mean and a little more posterior probability mass below 0.\n",
    "\n",
    "If we add an unobserved variable that influences discipline and funding, this analysis no longer works, because discipline is a collider between gender and our unobserved variable, so conditioning on gender opens a backdoor path."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Problem 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>density</th>\n",
       "      <th>pred</th>\n",
       "      <th>size</th>\n",
       "      <th>surv</th>\n",
       "      <th>propsurv</th>\n",
       "      <th>pred_id</th>\n",
       "      <th>size_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>10</td>\n",
       "      <td>no</td>\n",
       "      <td>big</td>\n",
       "      <td>9</td>\n",
       "      <td>0.900000</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "      <td>no</td>\n",
       "      <td>big</td>\n",
       "      <td>10</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>10</td>\n",
       "      <td>no</td>\n",
       "      <td>big</td>\n",
       "      <td>7</td>\n",
       "      <td>0.700000</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>10</td>\n",
       "      <td>no</td>\n",
       "      <td>big</td>\n",
       "      <td>10</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>10</td>\n",
       "      <td>no</td>\n",
       "      <td>small</td>\n",
       "      <td>9</td>\n",
       "      <td>0.900000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5</td>\n",
       "      <td>10</td>\n",
       "      <td>no</td>\n",
       "      <td>small</td>\n",
       "      <td>9</td>\n",
       "      <td>0.900000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>6</td>\n",
       "      <td>10</td>\n",
       "      <td>no</td>\n",
       "      <td>small</td>\n",
       "      <td>10</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>7</td>\n",
       "      <td>10</td>\n",
       "      <td>no</td>\n",
       "      <td>small</td>\n",
       "      <td>9</td>\n",
       "      <td>0.900000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>8</td>\n",
       "      <td>10</td>\n",
       "      <td>pred</td>\n",
       "      <td>big</td>\n",
       "      <td>4</td>\n",
       "      <td>0.400000</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>9</td>\n",
       "      <td>10</td>\n",
       "      <td>pred</td>\n",
       "      <td>big</td>\n",
       "      <td>9</td>\n",
       "      <td>0.900000</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>pred</td>\n",
       "      <td>big</td>\n",
       "      <td>7</td>\n",
       "      <td>0.700000</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>11</td>\n",
       "      <td>10</td>\n",
       "      <td>pred</td>\n",
       "      <td>big</td>\n",
       "      <td>6</td>\n",
       "      <td>0.600000</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>12</td>\n",
       "      <td>10</td>\n",
       "      <td>pred</td>\n",
       "      <td>small</td>\n",
       "      <td>7</td>\n",
       "      <td>0.700000</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>13</td>\n",
       "      <td>10</td>\n",
       "      <td>pred</td>\n",
       "      <td>small</td>\n",
       "      <td>5</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>14</td>\n",
       "      <td>10</td>\n",
       "      <td>pred</td>\n",
       "      <td>small</td>\n",
       "      <td>9</td>\n",
       "      <td>0.900000</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>15</td>\n",
       "      <td>10</td>\n",
       "      <td>pred</td>\n",
       "      <td>small</td>\n",
       "      <td>9</td>\n",
       "      <td>0.900000</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>16</td>\n",
       "      <td>25</td>\n",
       "      <td>no</td>\n",
       "      <td>big</td>\n",
       "      <td>24</td>\n",
       "      <td>0.960000</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>17</td>\n",
       "      <td>25</td>\n",
       "      <td>no</td>\n",
       "      <td>big</td>\n",
       "      <td>23</td>\n",
       "      <td>0.920000</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>18</td>\n",
       "      <td>25</td>\n",
       "      <td>no</td>\n",
       "      <td>big</td>\n",
       "      <td>22</td>\n",
       "      <td>0.880000</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>19</td>\n",
       "      <td>25</td>\n",
       "      <td>no</td>\n",
       "      <td>big</td>\n",
       "      <td>25</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>20</td>\n",
       "      <td>25</td>\n",
       "      <td>no</td>\n",
       "      <td>small</td>\n",
       "      <td>23</td>\n",
       "      <td>0.920000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>21</td>\n",
       "      <td>25</td>\n",
       "      <td>no</td>\n",
       "      <td>small</td>\n",
       "      <td>23</td>\n",
       "      <td>0.920000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>22</td>\n",
       "      <td>25</td>\n",
       "      <td>no</td>\n",
       "      <td>small</td>\n",
       "      <td>23</td>\n",
       "      <td>0.920000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>23</td>\n",
       "      <td>25</td>\n",
       "      <td>no</td>\n",
       "      <td>small</td>\n",
       "      <td>21</td>\n",
       "      <td>0.840000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>24</td>\n",
       "      <td>25</td>\n",
       "      <td>pred</td>\n",
       "      <td>big</td>\n",
       "      <td>6</td>\n",
       "      <td>0.240000</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>25</td>\n",
       "      <td>25</td>\n",
       "      <td>pred</td>\n",
       "      <td>big</td>\n",
       "      <td>13</td>\n",
       "      <td>0.520000</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>26</td>\n",
       "      <td>25</td>\n",
       "      <td>pred</td>\n",
       "      <td>big</td>\n",
       "      <td>4</td>\n",
       "      <td>0.160000</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>27</td>\n",
       "      <td>25</td>\n",
       "      <td>pred</td>\n",
       "      <td>big</td>\n",
       "      <td>9</td>\n",
       "      <td>0.360000</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>28</td>\n",
       "      <td>25</td>\n",
       "      <td>pred</td>\n",
       "      <td>small</td>\n",
       "      <td>13</td>\n",
       "      <td>0.520000</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>29</td>\n",
       "      <td>25</td>\n",
       "      <td>pred</td>\n",
       "      <td>small</td>\n",
       "      <td>20</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>30</td>\n",
       "      <td>25</td>\n",
       "      <td>pred</td>\n",
       "      <td>small</td>\n",
       "      <td>8</td>\n",
       "      <td>0.320000</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>31</td>\n",
       "      <td>25</td>\n",
       "      <td>pred</td>\n",
       "      <td>small</td>\n",
       "      <td>10</td>\n",
       "      <td>0.400000</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>32</td>\n",
       "      <td>35</td>\n",
       "      <td>no</td>\n",
       "      <td>big</td>\n",
       "      <td>34</td>\n",
       "      <td>0.971429</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>33</td>\n",
       "      <td>35</td>\n",
       "      <td>no</td>\n",
       "      <td>big</td>\n",
       "      <td>33</td>\n",
       "      <td>0.942857</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>34</td>\n",
       "      <td>35</td>\n",
       "      <td>no</td>\n",
       "      <td>big</td>\n",
       "      <td>33</td>\n",
       "      <td>0.942857</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>35</td>\n",
       "      <td>35</td>\n",
       "      <td>no</td>\n",
       "      <td>big</td>\n",
       "      <td>31</td>\n",
       "      <td>0.885714</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>36</td>\n",
       "      <td>35</td>\n",
       "      <td>no</td>\n",
       "      <td>small</td>\n",
       "      <td>31</td>\n",
       "      <td>0.885714</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>37</td>\n",
       "      <td>35</td>\n",
       "      <td>no</td>\n",
       "      <td>small</td>\n",
       "      <td>35</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>38</td>\n",
       "      <td>35</td>\n",
       "      <td>no</td>\n",
       "      <td>small</td>\n",
       "      <td>33</td>\n",
       "      <td>0.942857</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>39</td>\n",
       "      <td>35</td>\n",
       "      <td>no</td>\n",
       "      <td>small</td>\n",
       "      <td>32</td>\n",
       "      <td>0.914286</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>40</td>\n",
       "      <td>35</td>\n",
       "      <td>pred</td>\n",
       "      <td>big</td>\n",
       "      <td>4</td>\n",
       "      <td>0.114286</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>41</td>\n",
       "      <td>35</td>\n",
       "      <td>pred</td>\n",
       "      <td>big</td>\n",
       "      <td>12</td>\n",
       "      <td>0.342857</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>42</td>\n",
       "      <td>35</td>\n",
       "      <td>pred</td>\n",
       "      <td>big</td>\n",
       "      <td>13</td>\n",
       "      <td>0.371429</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>43</td>\n",
       "      <td>35</td>\n",
       "      <td>pred</td>\n",
       "      <td>big</td>\n",
       "      <td>14</td>\n",
       "      <td>0.400000</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>44</td>\n",
       "      <td>35</td>\n",
       "      <td>pred</td>\n",
       "      <td>small</td>\n",
       "      <td>22</td>\n",
       "      <td>0.628571</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>45</td>\n",
       "      <td>35</td>\n",
       "      <td>pred</td>\n",
       "      <td>small</td>\n",
       "      <td>12</td>\n",
       "      <td>0.342857</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>46</td>\n",
       "      <td>35</td>\n",
       "      <td>pred</td>\n",
       "      <td>small</td>\n",
       "      <td>31</td>\n",
       "      <td>0.885714</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>47</td>\n",
       "      <td>35</td>\n",
       "      <td>pred</td>\n",
       "      <td>small</td>\n",
       "      <td>17</td>\n",
       "      <td>0.485714</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Unnamed: 0  density  pred   size  surv  propsurv  pred_id  size_id\n",
       "0            0       10    no    big     9  0.900000        0        1\n",
       "1            1       10    no    big    10  1.000000        0        1\n",
       "2            2       10    no    big     7  0.700000        0        1\n",
       "3            3       10    no    big    10  1.000000        0        1\n",
       "4            4       10    no  small     9  0.900000        0        0\n",
       "5            5       10    no  small     9  0.900000        0        0\n",
       "6            6       10    no  small    10  1.000000        0        0\n",
       "7            7       10    no  small     9  0.900000        0        0\n",
       "8            8       10  pred    big     4  0.400000        1        1\n",
       "9            9       10  pred    big     9  0.900000        1        1\n",
       "10          10       10  pred    big     7  0.700000        1        1\n",
       "11          11       10  pred    big     6  0.600000        1        1\n",
       "12          12       10  pred  small     7  0.700000        1        0\n",
       "13          13       10  pred  small     5  0.500000        1        0\n",
       "14          14       10  pred  small     9  0.900000        1        0\n",
       "15          15       10  pred  small     9  0.900000        1        0\n",
       "16          16       25    no    big    24  0.960000        0        1\n",
       "17          17       25    no    big    23  0.920000        0        1\n",
       "18          18       25    no    big    22  0.880000        0        1\n",
       "19          19       25    no    big    25  1.000000        0        1\n",
       "20          20       25    no  small    23  0.920000        0        0\n",
       "21          21       25    no  small    23  0.920000        0        0\n",
       "22          22       25    no  small    23  0.920000        0        0\n",
       "23          23       25    no  small    21  0.840000        0        0\n",
       "24          24       25  pred    big     6  0.240000        1        1\n",
       "25          25       25  pred    big    13  0.520000        1        1\n",
       "26          26       25  pred    big     4  0.160000        1        1\n",
       "27          27       25  pred    big     9  0.360000        1        1\n",
       "28          28       25  pred  small    13  0.520000        1        0\n",
       "29          29       25  pred  small    20  0.800000        1        0\n",
       "30          30       25  pred  small     8  0.320000        1        0\n",
       "31          31       25  pred  small    10  0.400000        1        0\n",
       "32          32       35    no    big    34  0.971429        0        1\n",
       "33          33       35    no    big    33  0.942857        0        1\n",
       "34          34       35    no    big    33  0.942857        0        1\n",
       "35          35       35    no    big    31  0.885714        0        1\n",
       "36          36       35    no  small    31  0.885714        0        0\n",
       "37          37       35    no  small    35  1.000000        0        0\n",
       "38          38       35    no  small    33  0.942857        0        0\n",
       "39          39       35    no  small    32  0.914286        0        0\n",
       "40          40       35  pred    big     4  0.114286        1        1\n",
       "41          41       35  pred    big    12  0.342857        1        1\n",
       "42          42       35  pred    big    13  0.371429        1        1\n",
       "43          43       35  pred    big    14  0.400000        1        1\n",
       "44          44       35  pred  small    22  0.628571        1        0\n",
       "45          45       35  pred  small    12  0.342857        1        0\n",
       "46          46       35  pred  small    31  0.885714        1        0\n",
       "47          47       35  pred  small    17  0.485714        1        0"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "frogs = pd.read_csv('reedfrogs.csv', sep=',')\n",
    "frogs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Three models:\n",
    "1. 48 independent tanks\n",
    "2. Hierarchical varying intercepts\n",
    "3. Hierarchical varying intercepts, plus predation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/dylan/.conda/envs/info510/lib/python3.8/site-packages/pymc3/sampling.py:466: FutureWarning: In an upcoming release, pm.sample will return an `arviz.InferenceData` object instead of a `MultiTrace` by default. You can pass return_inferencedata=True or return_inferencedata=False to be safe and silence this warning.\n",
      "  warnings.warn(\n",
      "Auto-assigning NUTS sampler...\n",
      "Initializing NUTS using jitter+adapt_diag...\n",
      "Multiprocess sampling (4 chains in 4 jobs)\n",
      "NUTS: [a]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "        <style>\n",
       "            /* Turns off some styling */\n",
       "            progress {\n",
       "                /* gets rid of default border in Firefox and Opera. */\n",
       "                border: none;\n",
       "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "                background-size: auto;\n",
       "            }\n",
       "            .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "                background: #F44336;\n",
       "            }\n",
       "        </style>\n",
       "      <progress value='24000' class='' max='24000' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      100.00% [24000/24000 00:08<00:00 Sampling 4 chains, 0 divergences]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Sampling 4 chains for 2_000 tune and 4_000 draw iterations (8_000 + 16_000 draws total) took 9 seconds.\n"
     ]
    }
   ],
   "source": [
    "with pm.Model() as simple_model:\n",
    "    a = pm.Normal('a', 0, 1, shape = 48)\n",
    "    p = pm.math.invlogit(a)\n",
    "    y = pm.Binomial('y', n = frogs.density, p = p, observed = frogs.surv)\n",
    "    \n",
    "    trace_simple = pm.sample(4000, tune = 2000, target_accept = 0.9, chains = 4, cores = 4)\n",
    "    summary_simple = az.summary(trace_simple)\n",
    "    #pm.traceplot(trace_simple)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with pm.Model() as vi_model:\n",
    "    μ = pm.Normal('μ', 0, 2)\n",
    "    η = pm.Normal('η', 0, 1, shape = 48)\n",
    "    σ = pm.HalfCauchy('σ', 5)\n",
    "    \n",
    "    a = pm.Deterministic('a', μ + η * σ)\n",
    "    p = pm.math.invlogit(a)\n",
    "    y = pm.Binomial('y', n = frogs.density, p = p, observed = frogs.surv)\n",
    "    \n",
    "    trace_vi = pm.sample(4000, tune = 2000, target_accept = 0.9, chains = 4, cores = 4)\n",
    "    summary_vi = az.summary(trace_vi, var_names = ['μ', 'σ', 'a'])\n",
    "    #pm.traceplot(trace_simple)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with pm.Model() as vi_with_pred:\n",
    "    μ = pm.Normal('μ', 0, 2)\n",
    "    η = pm.Normal('η', 0, 1, shape = 48)\n",
    "    σ = pm.HalfCauchy('σ', 5)\n",
    "    \n",
    "    b = pm.Normal('b', 0, 2)\n",
    "    \n",
    "    a = pm.Deterministic('a', μ + η * σ)\n",
    "    p = pm.math.invlogit(a + b * frogs.pred_id)\n",
    "    y = pm.Binomial('y', n = frogs.density, p = p, observed = frogs.surv)\n",
    "    \n",
    "    trace_vip = pm.sample(4000, tune = 2000, target_accept = 0.9, chains = 4, cores = 4)\n",
    "    summary_vip = .summary(trace_vip, var_names = ['μ', 'σ', 'b', 'a'])\n",
    "    #pm.traceplot(trace_simple)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pm.compare({'simple':trace_simple, 'vi':trace_vi, 'vi_with_pred':trace_vip})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "summary_vip.iloc[0:3, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "summary_vi.iloc[0:2, :]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The WAIC shows little difference in predictive accuracy among the three models. The reduced value of $\\sigma$ in the model including predation is because some of the variation between tanks is due to the fact that some tanks have predators and others don't. If this is accounted for by a coefficient in the model, we don't need as high a variance between tanks."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Problem 5\n",
    "\n",
    "First, read the data and compute the proportions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "naes_data = pd.read_csv('naes_grouped.csv', index_col = 0)\n",
    "naes_data['prop'] = naes_data['yes'] / naes_data['n']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up data for the GP fit\n",
    "age = naes_data['age'].values[:, None]\n",
    "p = naes_data['prop'].values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We set up a GP model using the `Marginal` class from PyMC3 (we don't need anything fancier) using the `marginal_likelihood` method to construct the model and `find_MAP` to fit it. The Matern_{3/2} prior is chosen pretty arbitrarily here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with pm.Model() as gp_model:\n",
    "    eta_process = pm.HalfCauchy('eta_process', 1)\n",
    "    l_process = pm.Gamma('l_process', 5, 1)         # somewhat arbitrarily pick a characteristic time scale of 5 years\n",
    "    cov_process = (eta_process ** 2) * pm.gp.cov.Matern32(1, l_process)\n",
    "    gp = pm.gp.Marginal(cov_func = cov_process)\n",
    "    \n",
    "    eta_noise = pm.HalfNormal('eta_noise', 2)\n",
    "    sigma_noise = pm.HalfCauchy('sigma_noise', 2)\n",
    "    cov_noise = (eta_noise ** 2) * pm.gp.cov.WhiteNoise(sigma_noise)\n",
    "    \n",
    "    # Since the normal noise model and the GP are conjugates, we use `Marginal` with the `.marginal_likelihood` method\n",
    "    y_ = gp.marginal_likelihood(\"y\", X=age, y=p, noise=cov_noise)\n",
    "\n",
    "    # this line calls an optimizer to find the MAP\n",
    "    map_est = pm.find_MAP(include_transformed = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tnew = np.arange(min(age)-3, max(age)+3, 0.1)[:, None]\n",
    "\n",
    "print(\"Predicting with gp ...\")\n",
    "mu, var = gp.predict(tnew, point=map_est, diag=True)\n",
    "#mean_pred = mu*std_pm + mean_pm\n",
    "#var_pred  = var*std_pm**2\n",
    "\n",
    "# make dataframe to store fit results\n",
    "fit = pd.DataFrame({\"t\": tnew.flatten(),\n",
    "                    \"mu_total\": mu, #mean_pred,\n",
    "                    \"sd_total\": np.sqrt(var)}\n",
    "                   )\n",
    "print(\"Done\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below we plot the GP fit with a 2 SD band. We're extending predictions a few years past the bounds of the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(14,8))\n",
    "plt.title('Proportion vs. age for the NAES data')\n",
    "plt.xlabel('Age')\n",
    "plt.ylabel('Proportion of \"yes\" answers')\n",
    "plt.plot(tnew, fit.mu_total, label = 'GP fit')\n",
    "plt.fill_between(x=tnew.flatten(), y1=fit.mu_total - 2*fit.sd_total, y2 = fit.mu_total + 2*fit.sd_total, color = 'lightblue')\n",
    "plt.plot(age, p, 'k.', label = 'Observed proportions')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Problem 6\n",
    "\n",
    "Functions below to generate the data and run the filter. Note the same dynamics used in each process."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_initial_velocity():\n",
    "    v = sp.stats.norm(400, 20).rvs()\n",
    "    angle = sp.stats.norm(np.pi/2, 0.1).rvs()\n",
    "    vx = v * np.cos(angle)\n",
    "    vy = v * np.sin(angle)\n",
    "    return vx, vy\n",
    "\n",
    "def generate_data(N, dt):\n",
    "    # Set up initial state\n",
    "    x, y = 0., 0.\n",
    "    vx, vy = get_initial_velocity()\n",
    "    state = np.array([x, vx, y, vy])\n",
    "    \n",
    "    # Set up dynamics matrices\n",
    "    A = np.array([[1, dt, 0, 0], [0, 1, 0, 0], [0, 0, 1, dt], [0, 0, 0, 1]])\n",
    "    B = np.array([[0,  0, 0, 0], [0, 0, 0, 0], [0, 0, -4.9 * dt ** 2, 0], [0, 0, 0, -9.8 * dt]])\n",
    "\n",
    "    # Generate states with dynamical system\n",
    "    state_seq = np.zeros((4, N))\n",
    "    state_seq[:,0] = state\n",
    "    for i in range(1, N):\n",
    "        state_seq[:, i] = A @ state + B @ np.array([0, 0, 1, 1])\n",
    "        state = state_seq[:, i]\n",
    "        \n",
    "    # Generate measurements\n",
    "    measurements = np.zeros((4, N - 1))\n",
    "    for i in range(N-1):\n",
    "        measurements[:, i] = state_seq[:, i] + sp.stats.multivariate_normal(mean=np.array([0, 0, 0, 0]), \n",
    "                                                                            cov=np.array([[100, 0, 0, 0], [0, 0.25, 0, 0], [0, 0, 100, 0], [0, 0, 0, 0.25]])).rvs()\n",
    "    return state_seq, measurements\n",
    "    \n",
    "def run_filter(measurements, dt, R):\n",
    "    # Set up dynamics matrices\n",
    "    A = np.array([[1, dt, 0, 0], [0, 1, 0, 0], [0, 0, 1, dt], [0, 0, 0, 1]])\n",
    "    B = np.array([[0,  0, 0, 0], [0, 0, 0, 0], [0, 0, -4.9 * dt ** 2, 0], [0, 0, 0, -9.8 * dt]])\n",
    "    \n",
    "    # Set up initial guess\n",
    "    x, y = 0., 0.\n",
    "    vx, vy = 0, 400\n",
    "    state = np.array([x, vx, y, vy])\n",
    "    \n",
    "    state_seq = np.zeros((4, measurements.shape[1]))\n",
    "    state_seq[:,0] = state\n",
    "    \n",
    "    # Set up covariance matrices. Using something close to 0 for the process noise.\n",
    "    P = np.eye(4)\n",
    "    Q = 1e-4 * np.eye(4)\n",
    "    \n",
    "    for i in range(1, measurements.shape[1]):\n",
    "        # Time update\n",
    "        new_state = A @ state + B @ np.array([0, 0, 1, 1])\n",
    "        P = P + Q\n",
    "        \n",
    "        # Measurement update\n",
    "        K = P @ np.linalg.inv(P + R)\n",
    "        new_est = new_state + K @ (measurements[:, i] - new_state)\n",
    "        P = (np.eye(4) - K) @ P\n",
    "        state_seq[:, i] = new_est\n",
    "        state = new_est\n",
    "        #print(P)\n",
    "    return state_seq"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we generate some data. By experimentation, about 700 time steps is usually a good amount to see what's going on."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "states, measurements = generate_data(700, 0.1)\n",
    "plt.figure(figsize=(16, 16))\n",
    "plt.plot(states[0, :], states[2, :], '--', label = 'true path')\n",
    "plt.plot(measurements[0, :], measurements[2, :], 'r.', label = 'measurements')\n",
    "plt.xlabel('x position')\n",
    "plt.ylabel('y position')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A few choices of measurement noise covariance are below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "R = np.array([[100, 0, 0, 0], [0, 0.25, 0, 0], [0, 0, 100, 0], [0, 0, 0, 0.25]])\n",
    "#R = 1000 * np.eye(4)\n",
    "#R = 0.001 * np.eye(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "est = run_filter(measurements, 0.1, R)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(16, 16))\n",
    "plt.plot(states[0, :], states[2, :], '--', label = 'true path')\n",
    "plt.plot(measurements[0, :], measurements[2, :], 'r.', label = 'measurements')\n",
    "plt.plot(est[0, :], est[2, :], 'k', label = 'estimated path', alpha = 0.7)\n",
    "plt.xlabel('x position')\n",
    "plt.ylabel('y position')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we can see, if we choose the true values for the measurement noise covariance the filter tracks the true trajectory very well. If $R$ is made very small, the estimated path is noisier, as it follows the data more closely. If $R$ is made very large, the estimation is very bad, because we trust initial guesses of the velocity too much. (Large noise variance on the position estimates is less harmful.) Tuning by hand shows $R = 10I$ to be a reasonably effective value if we don't know anything about the measurement covariance *a priori.*"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
